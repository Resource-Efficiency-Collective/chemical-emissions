{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Calculate EF for each process from input data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fcef4ad7d87f070d"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Import packages\n",
    "import os\n",
    "import warnings\n",
    "from process_iteration_functions import *\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented.*\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"RuntimeWarning: Mean of empty slice.*\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"FutureWarning: The behavior of DataFrame.*\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"FutureWarning: The provided callable*\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Data file paths - ## REPLACE '_demo' files with calculated files when conducting real run\n",
    "input_path = '../data/'\n",
    "\n",
    "output_path = input_path+'test_output/'\n",
    "os.mkdir(output_path) if not os.path.exists(output_path) else None\n",
    "\n",
    "ihs_materials_path = input_path+'processed/ihsMaterials_w_uncertainties_demo.csv'\n",
    "direct_energyUse_conversion_path = input_path+'extra_inputs/direct_utility_conversion_factors.csv'\n",
    "direct_process_path = input_path+'extra_inputs/Direct process emissions.xlsx'\n",
    "\n",
    "ecoinvent_file = input_path+'extracted/EI_3_10_APOS_EFs_in_IHS_demo.csv'\n",
    "carbonMinds_file = input_path+'processed/conversionFactors_carbonMinds_grouped_demo.csv'\n",
    "ifa_file = input_path+'extracted/conversionFactors_from_IFA_w_uncertainties_demo.csv'\n",
    "\n",
    "match_list_path = input_path+'processed/ihs_to_ei_matches_formatted_demo.csv'\n",
    "\n",
    "product_group_path = input_path+'extra_inputs/product_groups.csv'\n",
    "\n",
    "production_file = input_path+'processed/icisFacilityProduction_dedoubled_demo.csv'\n",
    "icis_ihs_match_file = input_path+'extra_inputs/all_icis_to_ihs_matches_24.csv'\n",
    "\n",
    "ammonia_processes_file = input_path+'extra_inputs/ammonia_processes_used.csv'\n",
    "fert_production_file = input_path+'extracted/IFA_country_production_demo.csv'\n",
    "\n",
    "ethylene_feedstocks_file = input_path+'extracted/icisEthyleneFeedstocks_1978-2050_demo.csv'\n",
    "ethylene_feedstock_types_file = input_path+'extra_inputs/feedstock_type.csv'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "16b925649d3153bd",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Import IHS process recipes\n",
    "ihs_materials = pd.read_csv(ihs_materials_path, index_col=0)\n",
    "\n",
    "# Direct energy use conversion \n",
    "direct_utl_conv = pd.read_csv(direct_energyUse_conversion_path, index_col=0)\n",
    "\n",
    "# Direct process conversion\n",
    "direct_process_efs = pd.read_excel(direct_process_path, skiprows=2)[1:].dropna(subset=['Process']).sort_values('Process').reset_index(drop=True)\n",
    "product_process_match = pd.read_csv(input_path+'extra_inputs/product_to_directProcess_matches.csv')\n",
    "\n",
    "# Import conversion factors\n",
    "ei_emissions = pd.read_csv(ecoinvent_file, index_col=0)\n",
    "cm_emissions = pd.read_csv(carbonMinds_file, index_col=0)\n",
    "ifa_factors = pd.read_csv(ifa_file, index_col=0)\n",
    "\n",
    "# Import match lists\n",
    "match_list_ei = pd.read_csv(match_list_path, index_col=False, usecols=['IHS','ei'])\n",
    "match_list_cm = pd.read_csv(match_list_path, index_col=False, usecols=['IHS','cm'])\n",
    "\n",
    "# Import chemical type list\n",
    "product_group = pd.read_csv(product_group_path, index_col=0).rename(columns={'PRODUCT':'Product'})\n",
    "\n",
    "ihs_prod_names = pd.read_csv(input_path+'extra_inputs/ihs_product_names.csv')\n",
    "name_convs = dict(zip(ihs_prod_names['IHS_NAME'], ihs_prod_names['ICIS_NAME']))\n",
    "ihs_materials['Product'] = ihs_materials['Product'].replace(name_convs)\n",
    "\n",
    "ihs_materials = ihs_materials.merge(product_group, on='Product', how='left')\n",
    "\n",
    "# Calculate direct process conversions\n",
    "direct_process_convs = calc_direct_process_convs(direct_process_efs, product_process_match, ei_emissions)\n",
    "direct_process_convs['Product'] = direct_process_convs['Product'].replace(name_convs)\n",
    "\n",
    "input_types = pd.concat((product_group, \n",
    "                         pd.read_csv(input_path+'extra_inputs/raw_material_types.csv', index_col=0).reset_index(drop=True).rename(columns={'PRODUCT':'Product'}))).rename(columns={'Product group':'Input_group', 'Product type':'Input_type', 'Product':'Source/Object'})\n",
    "\n",
    "# Replace Type for raw materials based on matching product type in input types \n",
    "ihs_materials = ihs_materials.merge(input_types, on='Source/Object', how='left')\n",
    "ihs_materials['Type'] = ihs_materials.apply(lambda x: x['Input_group'] if x['Type'] == 'Raw Material' and pd.notna(x['Input_group']) else x['Type'], axis=1)\n",
    "ihs_materials.drop(columns=['Input_group', 'Input_type'], inplace=True)\n",
    "\n",
    "ammonia_processes = pd.read_csv(ammonia_processes_file, index_col=0)\n",
    "ifa_production = import_ifa(fert_production_file)\n",
    "\n",
    "icis_ihs_matches = pd.read_csv(icis_ihs_match_file, index_col=0)\n",
    "facility_production = pd.read_csv(production_file, index_col=0)\n",
    "\n",
    "ethylene_feedstocks = pd.read_csv(ethylene_feedstocks_file, index_col=0, header=[0,1])\n",
    "ethylene_feedstock_vals = get_ethylene_feedstock_vals(facility_production, ethylene_feedstocks)\n",
    "\n",
    "ethylene_feedstock_types = pd.read_csv(ethylene_feedstock_types_file)\n",
    "\n",
    "# Add on bio processes\n",
    "bio_forecast, weighting = False, False\n",
    "\n",
    "if bio_forecast:\n",
    "    extra_processes = pd.read_csv(input_path+'extra_inputs/benzene_toluene_process.csv')\n",
    "    \n",
    "    bt_matches = icis_ihs_matches[icis_ihs_matches['PRODUCT'].isin(['BENZENE', 'TOLUENE'])]\n",
    "    bt_matches['ihs_match'] = extra_processes['Target/Process'].unique()[0]\n",
    "    bt_matches = bt_matches.drop_duplicates()\n",
    "    icis_ihs_matches = pd.concat((icis_ihs_matches[~icis_ihs_matches['PRODUCT'].isin(['BENZENE', 'TOLUENE'])], bt_matches))    \n",
    "\n",
    "    bio_conv_factors = pd.read_csv(input_path+'extra_inputs/bio_EFs.csv', index_col=0)\n",
    "    bio_processes = pd.read_csv(input_path+'extra_inputs/bio_processes.csv')\n",
    "\n",
    "    # Replace primary chemical processes with bio routes\n",
    "    ihs_materials = pd.concat((ihs_materials[ihs_materials['Target/Process'].isin(bio_processes['Target/Process'])],\n",
    "           ihs_materials[~ihs_materials['Product'].isin(bio_processes['Product'].unique())]))\n",
    "\n",
    "    # Replace feedstock emissions factors with bio factors\n",
    "    for source in bio_conv_factors['Source']:\n",
    "        ind = ei_emissions[ei_emissions['Source']==source].index\n",
    "        ei_emissions.loc[ind] = bio_conv_factors[bio_conv_factors['Source']==source].values"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "264f68f456bb608d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "coal_use = {'China': 0.829268293,\n",
    "            'USA': 0.034883721}\n",
    "\n",
    "ammonia_weight = ifa_production[ifa_production['PRODUCT']=='AMMONIA']\n",
    "ammonia_weight['ROUTE'] = 'SR'\n",
    "ammonia_weight['coal_conv'] = ammonia_weight['COUNTRY/TERRITORY'].map(coal_use).fillna(0)\n",
    "ammonia_weight['gas_conv'] = 1-ammonia_weight['coal_conv']\n",
    "\n",
    "# Multiply all values by coal conversion factor\n",
    "ammonia_coal = ammonia_weight[ammonia_weight['coal_conv']>0]\n",
    "ammonia_gas = ammonia_weight.copy()\n",
    "for year in range(1978, 2051):\n",
    "    ammonia_coal[str(year)] = ammonia_coal[str(year)].multiply(ammonia_coal['coal_conv'], axis=0)\n",
    "    ammonia_coal[str(year)+'_sigma'] = ammonia_coal[str(year)+'_sigma'].multiply(ammonia_coal['coal_conv'], axis=0)\n",
    "    ammonia_gas[str(year)] = ammonia_gas[str(year)].multiply(ammonia_gas['gas_conv'], axis=0)\n",
    "    ammonia_gas[str(year)+'_sigma'] = ammonia_gas[str(year)+'_sigma'].multiply(ammonia_gas['gas_conv'], axis=0)\n",
    "ammonia_coal['ROUTE'] = 'Coal'\n",
    "\n",
    "ammonia_weight = pd.concat((ammonia_coal, ammonia_gas)).drop(columns=['coal_conv', 'gas_conv'])\n",
    "ifa_production = pd.concat((ifa_production[ifa_production['PRODUCT']!='AMMONIA'], ammonia_weight))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2cf71a5801096246",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Calculation loop\n",
    "groups = ['Primary chemicals', 'Primary chemicals', 'Primary chemicals', 'Primary chemicals', 'Intermediates', 'Intermediates', 'Intermediates', 'Downstream', 'Downstream']\n",
    "group_output_names = ['PC1', 'PC2', 'PC3', 'PC4', 'IC1', 'IC2', 'IC3', 'DS1', 'DS2']\n",
    "\n",
    "for current_group, current_group_name in zip(groups, group_output_names):\n",
    "    if current_group_name in ['PC4', 'IC3', 'DS2']:\n",
    "        output_iteration = True\n",
    "    else: output_iteration = False\n",
    "    \n",
    "    print(current_group_name)\n",
    "    # Fetch chemicals at this stage of production\n",
    "    current_chemical_names = product_group[product_group['Product type']==current_group]['Product']\n",
    "    current_chemicals = ihs_materials[ihs_materials['Product type']==current_group]\n",
    "\n",
    "    if len(current_chemicals) == 0:\n",
    "        print('No '+current_group+' included in current data.')\n",
    "        continue\n",
    "    \n",
    "    # Calculate material emissions for each process\n",
    "    material_emissions = get_upstream_emissions(current_chemicals, ei_emissions, cm_emissions, match_list_ei, match_list_cm)\n",
    "    material_emissions['Type'] = material_emissions['Type'].replace({'Utilities':'Indirect Utilities'})\n",
    "    material_emissions = get_direct_energy_emissions(material_emissions, direct_utl_conv, ei_emissions)\n",
    "    material_emissions = get_direct_process_emissions(material_emissions, direct_process_convs)\n",
    "    \n",
    "    if bio_forecast:\n",
    "        # Load in bio processes and split benzene and toluene routes\n",
    "        material_emissions = pd.concat((material_emissions[material_emissions['Product']!='BENZENE AND TOLUENE'], extra_processes))\n",
    "    print('Materials done.')\n",
    "    \n",
    "    # Allocation emissions from all materials to each co-product from processes\n",
    "    emission_val_cols = list(ei_emissions.columns[3:16])\n",
    "    mass_allocation = allocate_emissions(material_emissions.copy(), emission_val_cols)\n",
    "    ## Add here if doing for energy and economic allocation\n",
    "    combined_factors = calculate_implied_emissions_factors(mass_allocation, material_emissions, emission_val_cols, suffixes=[''])\n",
    "    combined_factors = add_ifa_conv_factors(combined_factors, ifa_factors)\n",
    "\n",
    "    # Only keep conversion factors needed for this round\n",
    "    cf_subset = combined_factors[combined_factors['Product'].isin(product_group[product_group['Product type']==current_group]['Product'])].dropna(subset=['ihs_match'])\n",
    "    cf_subset = cf_subset.fillna(0)\n",
    "        \n",
    "    cf_subset.to_csv(output_path+'processConversionFactors_'+current_group_name+'_.csv')\n",
    "    print('EFs done')\n",
    "    \n",
    "    ## Assign processes to facilities\n",
    "    # Filter out outlying possible processes\n",
    "    poss_processes = icis_ihs_matches[icis_ihs_matches['PRODUCT'].isin(product_group[product_group['Product type']==current_group]['Product'])].merge(\n",
    "        cf_subset, left_on=['ihs_match'], right_on=['ihs_match'], how='left')\n",
    "    \n",
    "    current_facilities = facility_production[facility_production['PRODUCT'].isin(product_group[product_group['Product type']==current_group]['Product'])]\n",
    "    \n",
    "    facility_conversion = merge_matching_processes(current_facilities, poss_processes)\n",
    "\n",
    "    current_ifa = ifa_production[ifa_production['PRODUCT'].isin(product_group[product_group['Product type']==current_group]['Product'])]\n",
    "    \n",
    "    facility_conversion = add_ifa_production(facility_conversion, current_ifa, cf_subset, ammonia_processes)\n",
    "    \n",
    "    ## Calculate facility emissions\n",
    "    ### -> Misses products with no IHS match\n",
    "    facility_conversion_orig = facility_conversion.dropna(subset=['ihs_match']).merge(cf_subset, on=['ihs_match'], how='left')\n",
    "    \n",
    "    if output_iteration:\n",
    "        dbs, names = None, None\n",
    "    else: \n",
    "        dbs, names = ['ihs_cradle-to-out-gate '], ['IHS CtOG']\n",
    "    \n",
    "    facility_emissions = calculate_facility_emissions(facility_conversion_orig, dbs=dbs, names=names, emission_val_cols=emission_val_cols)\n",
    "    \n",
    "    aggregated_emissions = aggregate_facility_emissions(facility_emissions)\n",
    "    \n",
    "    if current_group == 'Primary chemicals' and bio_forecast is False and weighting is True:\n",
    "        ethylene_conv_factors = calculate_ethylene_feedstock_emissions(cf_subset, ethylene_feedstock_types)\n",
    "        ethylene_facility_factors = attribute_weighted_ethylene_to_facilities(ethylene_feedstock_vals, ethylene_conv_factors)\n",
    "        \n",
    "        emissions_weighted = merge_weighted_ethylene(aggregated_emissions, ethylene_facility_factors, dbs=dbs, names=names)\n",
    "    \n",
    "    else: emissions_weighted = aggregated_emissions.copy()\n",
    "    \n",
    "    emissions_weighted.to_parquet(output_path+'facilityEmissions_'+current_group_name+'_.parquet')\n",
    "    \n",
    "    ## Calculate EFs for next iteration\n",
    "    iteration_ef_updates = get_updated_efs(facility_production, current_ifa, emissions_weighted, current_chemical_names, cf_subset)\n",
    "    iteration_ef_updates.to_csv(output_path+'average_efs_'+current_group_name+'_.csv')\n",
    "    \n",
    "    if output_iteration == False:\n",
    "        ei_emissions, match_list_ei, cm_emissions, match_list_cm = update_ef_dfs(ei_emissions, match_list_ei, cm_emissions, match_list_cm, iteration_ef_updates, current_chemical_names)\n",
    "\n",
    "\n",
    "print('Processing finished')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4694f08393767d4e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## Check facilities emissions file if desired\n",
    "test_file = pd.read_parquet('INSERT FINAL OUTPUT PARQUET FILEPATH')"
   ],
   "id": "e966d259ca331723",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "test_file.head(10)",
   "id": "72e5fea9dcb673a8",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# def update_ef_dfs(ei_emissions, match_list_ei, cm_emissions, match_list_cm, iteration_ef_updates, current_chemical_names):\n",
    "#     \"\"\"Update EFs with new values from iteration to use in next iteration\"\"\"\n",
    "#     iteration_ef_updates = iteration_ef_updates[iteration_ef_updates['CO2e_100a']!=0] # Remove non produced items\n",
    "#     iteration_ef_updates['PRODUCT'] = iteration_ef_updates['PRODUCT'].str.replace('BTX', 'REFORMATE')\n",
    "#\n",
    "#     iteration_ef_updates['Source'] = iteration_ef_updates['PRODUCT'].str.lower()\n",
    "#     iteration_ef_updates['generalComment'] = 'C-THRU calculation'\n",
    "#     iteration_ef_updates['location'] = 'GLO'\n",
    "#     iteration_ef_updates['Product'] = iteration_ef_updates['PRODUCT'].str.lower()\n",
    "#     iteration_ef_updates = iteration_ef_updates.drop(columns=['PRODUCT'])\n",
    "#     iteration_ef_updates = iteration_ef_updates[list(ei_emissions.columns)]\n",
    "#\n",
    "#     ei_updated = pd.concat((iteration_ef_updates, ei_emissions)).drop_duplicates(subset=['Source'], keep='first')\n",
    "#\n",
    "#     update_matches = iteration_ef_updates.copy()\n",
    "#     update_matches['ei'], update_matches['IHS'] = update_matches['Source'], update_matches['Source']\n",
    "#     ei_update_matches = match_list_ei[[i in update_matches['IHS'].unique() for i in match_list_ei['IHS']]]\n",
    "#     ei_update_matches = ei_update_matches[ei_update_matches['ei']!='0']\n",
    "#     ei_update_matches = ei_update_matches.set_index('ei')['IHS'].to_dict()\n",
    "#     match_list_ei['ei'] = match_list_ei['ei'].replace(ei_update_matches)\n",
    "#     # ei_equivalents = match_list_ei[match_list_ei['IHS'].isin(current_chemical_names.str.lower())]\n",
    "#     # ei_current_emissions = ei_equivalents.merge(ei_emissions, left_on='ei', right_on='Source', how='inner')\n",
    "#     # merged_updates = ei_current_emissions.merge(iteration_ef_updates, left_on='IHS', right_on=iteration_ef_updates['PRODUCT'].str.lower(), how='inner')\n",
    "#     # ei_updates = merged_updates[['Source', 'generalComment', 'location']+[col for col in merged_updates.columns if '_y' in col]]\n",
    "#     # ei_updates['location'], ei_updates['generalComment'] = 'GLO', 'C-THRU calculation'\n",
    "#     # ei_updates.columns = [col.replace('_y', '') for col in ei_updates.columns]\n",
    "#     #\n",
    "#     # ei_emissions = pd.concat((ei_updates, ei_emissions[~ei_emissions['Source'].isin(ei_updates['Source'])]))\n",
    "#\n",
    "#     cm_emissions = cm_emissions[~cm_emissions['Source'].isin(match_list_cm[match_list_cm['IHS'].isin(current_chemical_names.str.lower())]['cm'])]\n",
    "#\n",
    "#     #match_list_cm.loc[match_list_cm[match_list_cm['IHS'].isin(current_chemical_names.str.lower())].index, 'cm'] = '0'\n",
    "#\n",
    "#     current_chem_matches = match_list_ei.loc[list((match_list_ei[match_list_ei['IHS'].isin(current_chemical_names.str.lower())]['ei'] != '0').index)]['IHS']\n",
    "#\n",
    "#     #match_list_cm.loc[match_list_cm[match_list_cm['IHS'].isin(current_chem_matches.values)].index, 'cm'] = '0'\n",
    "#     match_list_cm.loc[match_list_cm['cm'].isin(match_list_cm[match_list_cm['IHS'].isin(current_chem_matches.str.lower())]['cm']), 'cm'] = '0'\n",
    "#\n",
    "#     return ei_updated, match_list_ei, cm_emissions, match_list_cm\n",
    "#\n",
    "# def get_updated_efs(facility_production, current_ifa, emissions_weighted, current_chemical_names, cf_subset):\n",
    "#\n",
    "#     production = pd.concat((facility_production, current_ifa.drop(columns=['Conv_name'])))\n",
    "#     current_group_prod = production[['PRODUCT', '2020', '2020_sigma']][production['PRODUCT'].isin(current_chemical_names)].groupby('PRODUCT').sum()\n",
    "#\n",
    "#     current_group_emissions = emissions_weighted[['PRODUCT', 'Gas', '2020', '2020_sigma']][emissions_weighted['PRODUCT'].isin(current_chemical_names)].groupby(['PRODUCT', 'Gas']).sum()\n",
    "#\n",
    "#     merged = current_group_emissions.reset_index().merge(current_group_prod, on='PRODUCT', how='left')\n",
    "#\n",
    "#     merged['EF'] = merged['2020_x'].values/merged['2020_y'].values\n",
    "#     merged['EF_sigma'] = merged['2020_sigma_x'].values/merged['2020_y'].values\n",
    "#\n",
    "#     # Pivot pandas df to have product as rows, gas as columns and EF as values\n",
    "#     efs = merged.pivot_table(index='PRODUCT', columns='Gas', values='EF').reset_index()\n",
    "#     ef_sigmas = merged.pivot_table(index='PRODUCT', columns='Gas', values='EF_sigma').reset_index()\n",
    "#     new_efs = efs.merge(ef_sigmas, on='PRODUCT', suffixes=('', '_sigma'))\n",
    "#\n",
    "#     non_produced_ef = cf_subset[~cf_subset['Product'].isin(new_efs['PRODUCT'])]\n",
    "#     non_produced_ef = non_produced_ef[['Product']+[col for col in non_produced_ef.columns if 'ihs' in col]].rename(columns={'Product':'PRODUCT'}).drop(columns=['ihs_match'])\n",
    "#     non_produced_ef.columns = pd.Series(non_produced_ef.columns).str.replace('ihs_cradle-to-out-gate ','').str.replace(',  allocation factor','').str.replace(',  allocation ','_')\n",
    "#     non_produced_ef[non_produced_ef.columns[1:]] = non_produced_ef[non_produced_ef.columns[1:]].astype(float)\n",
    "#     non_produced_ef = non_produced_ef.groupby('PRODUCT').mean().reset_index()\n",
    "#\n",
    "#     return pd.concat((new_efs, non_produced_ef))\n",
    "#\n",
    "# def merge_weighted_ethylene(facility_emissions, ethylene_conv, dbs=None, names=None, emission_val_cols=None):\n",
    "#\n",
    "#     if dbs is None:\n",
    "#         dbs = ['combined_', 'ihs_cradle-to-out-gate ', 'Feedstock ', 'Primary chemicals ', 'Intermediates ', 'Indirect Utilities ', 'Direct Utilities ', 'Direct Process ', 'Electricity ', 'Thermoplastics ', 'N-fertilisers ', 'Solvents, additives & explosives ', 'Thermosets, fibre & elastomers ', 'Other downstream ']\n",
    "#     if names is None:\n",
    "#         names = ['EI & CM', 'IHS CtOG', 'Feedstock', 'Primary chemicals', 'Intermediates', 'Direct Utilities', 'Indirect Utilities', 'Direct Process', 'Electricity', 'Thermoplastics', 'N-fertilisers', 'Solvents, additives & explosives', 'Thermosets, fibre & elastomers', 'Other downstream']\n",
    "#     if emission_val_cols is None:\n",
    "#         emission_val_cols = ['CO2e_20a', 'CO2e_100a', 'CO2e_500a', 'Carbon dioxide', 'Carbon monoxide', 'Chloroform', 'Dinitrogen monoxide', 'Ethane', 'Methane', 'Nitric oxide', 'Nitrogen fluoride', 'Perfluoropentane', 'Sulfur hexafluoride']\n",
    "#\n",
    "#     base_cols = list(ethylene_conv.columns[:7])\n",
    "#\n",
    "#     ethylene_vals = pd.DataFrame()\n",
    "#     ethylene_sigmas = pd.DataFrame()\n",
    "#     ethylene_conv['conversion'] = [i.replace(',  allocation factor', '').replace(',  allocation ','_') for i in ethylene_conv['conversion']]\n",
    "#\n",
    "#     for db, name in zip(dbs, names):\n",
    "#         for gas in emission_val_cols:\n",
    "#             df = ethylene_conv[ethylene_conv['conversion']==db+gas]\n",
    "#             df['Gas'] = gas\n",
    "#             df['Type'] = name\n",
    "#             ethylene_vals = pd.concat((ethylene_vals, df), axis = 0)\n",
    "#\n",
    "#             df_sigma = ethylene_conv[ethylene_conv['conversion']==db+gas+'_sigma']\n",
    "#             df_sigma['Gas'] = gas\n",
    "#             df_sigma['Type'] = name\n",
    "#             ethylene_sigmas = pd.concat((ethylene_sigmas, df_sigma), axis = 0)\n",
    "#\n",
    "#     ethylene_weighted = ethylene_vals.merge(ethylene_sigmas, on=base_cols+['Gas', 'Type'], how='left', suffixes=('','_sigma')).reset_index()\n",
    "#     #\n",
    "#     # #ethylene_weighted.columns.name = None\n",
    "#     ethylene_weighted = ethylene_weighted.fillna(0).drop(columns=['conversion', 'conversion_sigma', 'index'])\n",
    "#\n",
    "#     ethylene_weighted[['COUNTRY/TERRITORY', 'STATE', 'COMPANY', 'SITE', '#', 'START_YR', 'Type', 'Gas']] = ethylene_weighted[['COUNTRY/TERRITORY', 'STATE', 'COMPANY', 'SITE', '#', 'START_YR', 'Type', 'Gas']].astype(str)\n",
    "#\n",
    "#     eth_ems = facility_emissions[facility_emissions['PRODUCT']=='ETHYLENE']\n",
    "#\n",
    "#     emissions_merged = eth_ems.merge(ethylene_weighted, on=['COUNTRY/TERRITORY', 'STATE', 'COMPANY', 'SITE', '#', 'START_YR', 'Type', 'Gas'], how='left', suffixes=('_old',''))\n",
    "#\n",
    "#     years = [str(i) for i in range(1978, 2051)]\n",
    "#     years_sigma = [year+'_sigma' for year in years]\n",
    "#\n",
    "#     for year, uncert in zip(years, years_sigma):\n",
    "#         emissions_merged[year] = emissions_merged[year].fillna(emissions_merged[year+'_old'])\n",
    "#         emissions_merged[uncert] = emissions_merged[uncert].fillna(emissions_merged[uncert+'_old'])\n",
    "#\n",
    "#     eth_emissions_update = emissions_merged.drop(columns=list(emissions_merged.columns[['_old' in i for i in emissions_merged.columns]]) + ['START_MO'])\n",
    "#\n",
    "#     full_update = pd.concat((facility_emissions[facility_emissions['PRODUCT']!='ETHYLENE'], eth_emissions_update), axis=0)\n",
    "#\n",
    "#     full_update[years_sigma] = full_update[years_sigma].astype(float)\n",
    "#\n",
    "#     return full_update.sort_values(list(full_update.columns[:15]))\n",
    "#\n",
    "# def attribute_weighted_ethylene_to_facilities(feedstock_vals, filt_agg):\n",
    "#     years = list(map(str, list(range(1978, 2051))))\n",
    "#\n",
    "#     print('Attributing ethylene feedstock emissions...')\n",
    "#     # Apply emissions to each facility\n",
    "#     blank = feedstock_vals[feedstock_vals.columns[:7]]\n",
    "#     blank.columns = list(blank.columns.droplevel(1))\n",
    "#     conversions = filt_agg.columns[['allocation' in name for name in filt_agg.columns]]\n",
    "#\n",
    "#     for conversion in tqdm(conversions):\n",
    "#         fs_ems = filt_agg[conversion]\n",
    "#         each_conv = pd.DataFrame()\n",
    "#         for year in years:\n",
    "#             df = feedstock_vals[year]\n",
    "#             for fs in df.columns[1:]:\n",
    "#                 df[fs] = df[fs]*fs_ems.loc[fs]\n",
    "#             yearly = blank.copy()\n",
    "#             yearly['Year'] = year\n",
    "#             yearly[conversion] = np.sum(df[df.columns[1:]].values, axis=1)\n",
    "#             each_conv = pd.concat((each_conv,yearly), axis=0)\n",
    "#         conv_emissions = pd.concat((blank, each_conv.pivot(columns=['Year'], values=conversion)), axis=1)\n",
    "#         conv_emissions['conversion'] = conversion\n",
    "#         if conversion != conversions[0]:\n",
    "#             ethylene_ems = pd.concat((ethylene_ems, conv_emissions), axis=0)#.merge(each_conv, on=list(each_conv.columns[:8]), how='left')\n",
    "#         else: ethylene_ems = conv_emissions.copy()\n",
    "#\n",
    "#     # ethylene_conv = ethylene_ems.copy()\n",
    "#     # ethylene_conv = ethylene_conv[['mass' in i for i in ethylene_conv['conversion']]]\n",
    "#     # ethylene_conv['conversion'] = [i.replace(', mass allocation ','_').replace('_factor','') for i in ethylene_conv['conversion']]\n",
    "#     # ethylene_conv.columns = [i.replace(', mass allocation ','_').replace('_factor','') for i in ethylene_conv.columns]\n",
    "#\n",
    "#     return ethylene_ems\n",
    "#\n",
    "# def calculate_ethylene_feedstock_emissions(conv_factors, feedstock_types, exclusion_column = 'ihs_cradle-to-out-gate CO2e_20a,  allocation factor'):\n",
    "#     eth_conv = conv_factors[conv_factors['Product']=='ETHYLENE'].reset_index(drop=True)\n",
    "#     feedstock_emissions = eth_conv.merge(feedstock_types, on='ihs_match', how='left')\n",
    "#\n",
    "#     feedstock_emissions[exclusion_column] = feedstock_emissions[exclusion_column].astype(float)\n",
    "#     keep_match_locs = feedstock_emissions.groupby('Feedstock').apply(exclude_outliers).drop(columns=['Feedstock']).reset_index()['level_1']\n",
    "#     keep_matches = eth_conv.loc[keep_match_locs]\n",
    "#     keep_rows = feedstock_emissions['ihs_match'].isin(keep_matches['ihs_match'])\n",
    "#     feedstock_emissions = feedstock_emissions[keep_rows]\n",
    "#\n",
    "#     filt_agg = feedstock_emissions.drop(columns = ['Product', 'Product group', 'Product type', 'ei_match','cm_match','ihs_match']).groupby(['Feedstock']).mean()\n",
    "#\n",
    "#     ## Get technology uncertainty by taking stdev\n",
    "#     stdevs = feedstock_emissions[['Feedstock']+[i for i in feedstock_emissions.columns if 'ihs' in i and 'sigma' not in i]].drop(columns='ihs_match').groupby(['Feedstock']).agg(np.std)\n",
    "#\n",
    "#     # Keep largest uncertainty between technologies and others\n",
    "#     years_sigma = [i for i in feedstock_emissions.columns if 'ihs' in i and 'sigma' in i]\n",
    "#     filt_agg[years_sigma] = np.abs((stdevs.fillna(0).values-filt_agg.fillna(0)[years_sigma].values)/2)+np.minimum(stdevs.fillna(0).values, filt_agg.fillna(0)[years_sigma].values)\n",
    "#\n",
    "#     return filt_agg\n",
    "#\n",
    "# def get_ethylene_feedstock_vals(facility_production, feedstocks):\n",
    "#     # Get emissions for each feedstock\n",
    "#     years = list(map(str, list(range(1978, 2051))))\n",
    "#     # Ethylene feedstocks\n",
    "#\n",
    "#     feedstocks_orig = feedstocks.copy()\n",
    "#     feedstock_types = pd.read_csv(input_path+'extra_inputs/feedstock_type.csv')\n",
    "#\n",
    "#     feedstocks.columns = ['_'.join(col).strip() for col in feedstocks.columns.values]\n",
    "#\n",
    "#     eth_prod = facility_production[facility_production['PRODUCT']=='ETHYLENE']\n",
    "#     feedstock_matches = feedstocks.merge(eth_prod, how='left', left_on=list(feedstocks.columns[:6]),\n",
    "#                                          right_on=['COUNTRY/TERRITORY','STATE','COMPANY','SITE', '#', 'START_YR'])\n",
    "#\n",
    "#     capacity_cols = [i for i in feedstock_matches.columns if 'CAPACITY' in str(i)]\n",
    "#\n",
    "#     for col, year in zip(capacity_cols, years):\n",
    "#         feedstock_matches[col] = feedstock_matches[year]\n",
    "#\n",
    "#     feedstock_matches.drop(columns=list(facility_production.columns), inplace=True)\n",
    "#     feedstock_matches.columns = feedstocks_orig.columns\n",
    "#\n",
    "#     feedstock_vals = feedstock_matches.copy()\n",
    "#     for year in years:\n",
    "#         df = feedstock_vals[year]\n",
    "#         df['CAPACITY'] = df['CAPACITY'].apply(lambda x: re.sub(\"[^0-9.]\", \"0\", str(x))).astype(float)\n",
    "#         df[df.columns[1:]] = df[df.columns[1:]].multiply(df['CAPACITY']/100, axis='index')\n",
    "#         feedstock_vals[year] = df\n",
    "#\n",
    "#     return feedstock_vals\n",
    "#\n",
    "# def aggregate_facility_emissions(facility_emissions):\n",
    "#\n",
    "#     years = [str(i) for i in range(1978, 2051)]\n",
    "#     years_sigma = [year+'_sigma' for year in years]\n",
    "#\n",
    "#     print('Aggregating facility emissions...')\n",
    "#     facility_emissions[facility_emissions.columns[:13]] = facility_emissions[facility_emissions.columns[:13]].fillna('n.a.')\n",
    "#     facility_emissions[years] = facility_emissions[years].astype(float)\n",
    "#     facility_emissions[years_sigma] = facility_emissions[years_sigma].astype(float)\n",
    "#     # Take mean of possible emissions given different possible technologies for each facility\n",
    "#     aggregated_emissions = facility_emissions.drop(columns='PROCESS').groupby(list(facility_emissions.columns[:13])+['Gas','Type']).agg(np.mean)\n",
    "#     print('Facility mean done')\n",
    "#\n",
    "#     ## Get technology uncertainty by taking stdev\n",
    "#     stdevs = facility_emissions[list(facility_emissions.columns[:13])+['Gas','Type']+years].groupby(list(facility_emissions.columns[:13])+['Gas','Type']).agg(np.std)\n",
    "#     print('Facility stdev done')\n",
    "#\n",
    "#     # Keep largest uncertainty between technologies and others\n",
    "#     aggregated_emissions[years_sigma] = np.maximum(stdevs.fillna(0).values, aggregated_emissions.fillna(0)[years_sigma].values)\n",
    "#\n",
    "#     aggregated_emissions = aggregated_emissions.reset_index()\n",
    "#     aggregated_emissions[aggregated_emissions.columns[:15]] = aggregated_emissions[aggregated_emissions.columns[:15]].astype(str)\n",
    "#\n",
    "#     return aggregated_emissions\n",
    "#\n",
    "# def calculate_facility_emissions(facility_conversion_orig, dbs=None, names=None, emission_val_cols=None):\n",
    "#\n",
    "#     if dbs is None:\n",
    "#         dbs = ['combined_', 'ihs_cradle-to-out-gate ', 'Feedstock ', 'Primary chemicals ', 'Intermediates ', 'Indirect Utilities ', 'Direct Utilities ', 'Direct Process ', 'Electricity ', 'Thermoplastics ', 'N-fertilisers ', 'Solvents, additives & explosives ', 'Thermosets, fibre & elastomers ', 'Other downstream ']\n",
    "#     if names is None:\n",
    "#         names = ['EI & CM', 'IHS CtOG', 'Feedstock', 'Primary chemicals', 'Intermediates', 'Indirect Utilities', 'Direct Utilities', 'Direct Process', 'Electricity', 'Thermoplastics', 'N-fertilisers', 'Solvents, additives & explosives', 'Thermosets, fibre & elastomers', 'Other downstream']\n",
    "#     if emission_val_cols is None:\n",
    "#         emission_val_cols = ['CO2e_20a', 'CO2e_100a', 'CO2e_500a', 'Carbon dioxide', 'Carbon monoxide', 'Chloroform', 'Dinitrogen monoxide', 'Ethane', 'Methane', 'Nitric oxide', 'Nitrogen fluoride', 'Perfluoropentane', 'Sulfur hexafluoride']\n",
    "#\n",
    "#     for i, emission_val_col in tqdm(enumerate(emission_val_cols)):\n",
    "#         emission_val_col = [emission_val_col]\n",
    "#         emission_val_col_sigma = [col + '_sigma' for col in emission_val_col]\n",
    "#         facility_conversion = facility_conversion_orig.copy()\n",
    "#\n",
    "#         for column, col_sigma in tqdm(zip(emission_val_col, emission_val_col_sigma)):\n",
    "#\n",
    "#             if (len(facility_conversion['cm_' + column + '_conv_factor'].dropna()) == 0) or (sum(facility_conversion['cm_' + column + '_conv_factor'].dropna()) == 0):\n",
    "#                 facility_conversion['combined_' + column] = facility_conversion['ei_' + column + '_conv_factor']\n",
    "#                 facility_conversion['combined_' + col_sigma] = facility_conversion['ei_' + column + '_conv_factor_sigma']\n",
    "#             else:\n",
    "#                 facility_conversion['combined_' + column] = np.nanmean([facility_conversion['ei_' + column + '_conv_factor'], facility_conversion['cm_' + column + '_conv_factor']], axis=0)\n",
    "#                 facility_conversion['combined_' + col_sigma] = np.nanmean([facility_conversion['ei_' + column + '_conv_factor_sigma'], facility_conversion['cm_' + column + '_conv_factor_sigma']], axis=0)\n",
    "#\n",
    "#         facility_conversion = facility_conversion[facility_conversion.columns[['ei' not in col and 'cm' not in col for col in facility_conversion.columns]]]\n",
    "#\n",
    "#         facility_conversion.rename(columns={'ihs_match':'PROCESS'}, inplace=True)\n",
    "#\n",
    "#         facility_conversion.columns = [i.replace(',  allocation ','_').replace('_factor','') for i in facility_conversion.columns]\n",
    "#\n",
    "#         # Create base dataframe to use\n",
    "#         years = [str(i) for i in range(1978, 2051)]\n",
    "#         years_sigma = [year+'_sigma' for year in years]\n",
    "#         base_columns = ['PRODUCT', 'COUNTRY/TERRITORY', 'STATE', 'COMPANY', 'SITE', '#',\n",
    "#                'ROUTE', 'TECHNOLOGY', 'LICENSOR', 'START_YR', 'COMPLEX', 'LATITUDE', 'LONGITUDE', 'PROCESS'] + years + years_sigma\n",
    "#         base_df = facility_conversion[base_columns]\n",
    "#\n",
    "#         facility_emissions = pd.DataFrame()\n",
    "#         for db, name in tqdm(zip(dbs, names)):\n",
    "#             for gas in tqdm(emission_val_col):\n",
    "#                 if db+gas in facility_conversion.columns:\n",
    "#                     df = base_df.copy()\n",
    "#                     df[years] = df[years].multiply(facility_conversion[db+gas], axis='index')\n",
    "#                     ## Incorrect error propagation here\n",
    "#                     df[years_sigma] = df[years_sigma].multiply(facility_conversion[db+gas+'_sigma'], axis='index')\n",
    "#                     df['Gas'] = gas\n",
    "#                     df['Type'] = name\n",
    "#                     facility_emissions = pd.concat((facility_emissions, df), axis = 0)\n",
    "#\n",
    "#         os.mkdir(output_path+'temp_facility_ems') if not os.path.exists(output_path+'temp_facility_ems') else None\n",
    "#         facility_emissions.to_parquet(output_path+'temp_facility_ems/facilityEmissions_'+current_group_name+'_'+str(i)+'.parquet')\n",
    "#\n",
    "#     if len(emission_val_cols) > 1:\n",
    "#         facility_emissions = pd.concat([pd.read_parquet(output_path+'temp_facility_ems/facilityEmissions_'+current_group_name+'_'+str(i)+'.parquet') for i in range(len(emission_val_cols))], axis=0)\n",
    "#\n",
    "#     return facility_emissions\n",
    "#\n",
    "# def import_ifa(file_path):\n",
    "#     # name_conversions = {\n",
    "#     #     'NH3': 'AMMONIA',\n",
    "#     #     'AN': 'AMMONIUM NITRATE',\n",
    "#     #     'Ammonium nitrate (33.5-0-0) granulated': 'AMMONIUM NITRATE',\n",
    "#     #     'AS': 'AMMONIUM SULPHATE',\n",
    "#     #     'CAN': 'CALCIUM AMMONIUM NITRATE',\n",
    "#     #     'Calcium ammonium nitrate (27-0-0)': 'CALCIUM AMMONIUM NITRATE',\n",
    "#     #     'Urea (46-0-0)': 'UREA'\n",
    "#     # }\n",
    "#\n",
    "#     ifa_ihs_matches = {\n",
    "#         'AMMONIA':'AMMONIA',\n",
    "#         'AMMONIUM NITRATE': 'AMMONIUM NITRATE',#'AMMONIUM NITRATE FERTILIZER',\n",
    "#         'AMMONIUM SULPHATE': 'AMMONIUM SULPHATE',#'HYDROXYLAMMONIUM SULFATE',\n",
    "#         'CALCIUM AMMONIUM NITRATE': 'AMMONIUM NITRATE',#'AMMONIUM NITRATE FERTILIZER',\n",
    "#         'UREA': 'UREA', #'UREA, AGRICULTURAL GRADE'\n",
    "#     }\n",
    "#     ifa_production = pd.read_csv(file_path)\n",
    "#     #ifa_production['PRODUCT'] = ifa_production['PRODUCT'].replace(name_conversions)\n",
    "#     ifa_production.rename(columns={'Country':'COUNTRY/TERRITORY'}, inplace=True)\n",
    "#     ifa_production['Conv_name'] = ifa_production['PRODUCT'].replace(ifa_ihs_matches)\n",
    "#\n",
    "#     return ifa_production\n",
    "#\n",
    "# ## Add IFA production\n",
    "# def add_ifa_production(facility_conversion, ifa_production, conv_factors, ammonia_processes):\n",
    "#\n",
    "#     ## Exclude outliers\n",
    "#     if 'AMMONIA' in conv_factors['Product'].unique():\n",
    "#         conv_factors = conv_factors.merge(ammonia_processes, on='ihs_match', how='left')\n",
    "#         left_cols, right_cols = ['Conv_name', 'ROUTE'], ['Product', 'Type']\n",
    "#     else:\n",
    "#         left_cols, right_cols = ['Conv_name'], ['Product']\n",
    "#     poss_ifa = ifa_production.merge(conv_factors, left_on=left_cols, right_on=right_cols, how='left').drop(columns=['Conv_name', 'Product'])\n",
    "#     cols = ['PRODUCT', 'ROUTE']\n",
    "#     ifa_years = [str(i) for i in range(1978,2051)]\n",
    "#     # keep_rows = poss_ifa[cols+['ihs_match', 'ihs_cradle-to-out-gate CO2e_20a,  allocation factor']].groupby(cols).apply(exclude_outliers)\n",
    "#     # filt_ifa = poss_ifa.iloc[list(keep_rows.index.get_level_values(1))].reset_index(drop=True)\n",
    "#     ifa_conversion = poss_ifa[['COUNTRY/TERRITORY']+ifa_years+cols+[i+'_sigma' for i in ifa_years]+['ihs_match']]\n",
    "#\n",
    "#     facility_conversion = pd.concat((facility_conversion, ifa_conversion))\n",
    "#\n",
    "#     return facility_conversion\n",
    "#\n",
    "# def merge_matching_processes(facility_production, poss_processes, determinant_column = 'ihs_cradle-to-out-gate CO2e_20a,  allocation factor'):\n",
    "#     \"\"\"Function for getting unexcluded processes from IHS and ICIS matches\"\"\"\n",
    "#     cols = ['PRODUCT', 'ROUTE', 'TECHNOLOGY', 'LICENSOR']\n",
    "#     poss_processes[determinant_column] = poss_processes[determinant_column].astype(float)\n",
    "#     keep_rows = poss_processes[cols+['ihs_match', determinant_column]].groupby(cols).apply(exclude_outliers)\n",
    "#     filt_processes = poss_processes.iloc[list(keep_rows.index.get_level_values(4))].reset_index(drop=True)\n",
    "#     icis_ihs_matches = filt_processes[['ihs_match']+cols]\n",
    "#\n",
    "#     facility_conversion = facility_production.merge(icis_ihs_matches, on=cols, how='left')\n",
    "#     return facility_conversion\n",
    "#\n",
    "# # define a function to exclude outliers\n",
    "# def exclude_outliers(group, col='ihs_cradle-to-out-gate CO2e_20a,  allocation factor'):\n",
    "#\n",
    "#     if len(group) > 3:  # only exclude outliers if the group has more than 3 rows\n",
    "#         mean = np.mean(group[col])\n",
    "#         std = np.std(group[col])\n",
    "#         max_distance = std  # maximum distance from the mean to be considered an outlier\n",
    "#         distances = np.abs(group[col] - mean)  # calculate distances of each value to the mean\n",
    "#         filtered_group = group[distances <= max_distance]  # keep only values within the maximum distance\n",
    "#\n",
    "#         if len(filtered_group) < 3:  # if less than 3 rows remain, take the 3 closest to the mean\n",
    "#             group['dist'] = np.abs(group[col] - mean)\n",
    "#             closest_rows = group.nsmallest(3, 'dist', keep='all')\n",
    "#\n",
    "#             return closest_rows.drop(columns=['dist'])\n",
    "#         else:\n",
    "#             return filtered_group\n",
    "#     else:\n",
    "#         return group\n",
    "#\n",
    "#\n",
    "# # ## Weight ammonia conversion factor\n",
    "# # def weight_ammonia_conversion_factor(conv_factors, ammonia_processes, sr_percentage=0.8):\n",
    "# #     # IEAâ€™s ammonia roadmap only considered three key processes for producing ammonia synthesis gas: steam reforming of natural gas (with the highest share of production, 63%), coal gasification (34%), and partial oxidation/steam reforming of oil feedstocks such as naphtha, LPG and fuel oil (2%).\n",
    "# #     # Use only these for now and for scenario include green ammonia.\n",
    "# #\n",
    "# #     grouped_amm = conv_factors[conv_factors['Product']=='AMMONIA'].merge(ammonia_processes, on='ihs_match').drop(columns=['Product', 'Product type', 'Product group', 'ei_match', 'cm_match', 'ihs_match']).groupby('Type').mean()\n",
    "# #     amm_weighted = (1-sr_percentage)*grouped_amm.iloc[0, :]+sr_percentage*grouped_amm.iloc[1, :]\n",
    "# #\n",
    "# #     amm_df = pd.DataFrame(amm_weighted).transpose().drop(columns=['Total']).astype(float)\n",
    "# #     amm_df['Product'], amm_df['ihs_match'] = 'AMMONIA', 'WEIGHTED AMMONIA'\n",
    "# #     amm_df.index = [3000]\n",
    "# #     conv_factors = pd.concat((conv_factors[conv_factors['Product']!='AMMONIA'], amm_df))\n",
    "# #\n",
    "# #     return conv_factors\n",
    "#\n",
    "# def add_ifa_conv_factors(combined_factors, ifa_factors):\n",
    "#     ifa_factors['Product'] = ifa_factors['Product'].str.upper()\n",
    "#     ifa_matches = pd.read_csv(input_path+'extra_inputs/ifa_matches.csv')\n",
    "#     ifa_factors = ifa_factors.merge(ifa_matches.dropna(), on='Product', how='right').drop(columns='Product').rename(columns={'Match':'Product'})\n",
    "#\n",
    "#     combined_factors = combined_factors.merge(ifa_factors, on='Product', how='left')\n",
    "#\n",
    "#     return combined_factors\n",
    "#\n",
    "# def calculate_implied_emissions_factors(allocation_df, material_emissions, emission_val_cols, suffixes=['']):\n",
    "#     \"\"\"Function for calculating implied emissions factors from allocated emissions\"\"\"\n",
    "#\n",
    "#     total_allocation = allocation_df[allocation_df['Type']=='Product']\n",
    "#     IHS_emissions = total_allocation[['Target/Process', 'Product']+[i for i in total_allocation.columns if 'allocated' in i]]\n",
    "#     IHS_emissions.rename(columns={'Target/Process':'ihs_match'}, inplace=True)\n",
    "#\n",
    "#     group_names = ['Total', 'Raw Material', 'Primary chemicals', 'Intermediates', 'Direct Utilities', 'Indirect Utilities', 'Direct Process', 'Electricity', 'Thermoplastics', 'N-fertilisers', 'Solvents, additives & explosives', 'Thermosets, fibre & elastomers', 'Other downstream']\n",
    "#     output_names = ['ihs_cradle-to-out-gate ', 'Feedstock ', 'Primary chemicals ', 'Intermediates ', 'Direct Utilities ', 'Indirect Utilities ', 'Direct Process ', 'Electricity ', 'Thermoplastics ', 'N-fertilisers ', 'Solvents, additives & explosives ', 'Thermosets, fibre & elastomers ', 'Other downstream ']\n",
    "#\n",
    "#     for suffix in suffixes:\n",
    "#         for group_name, output_name in zip(group_names, output_names):\n",
    "#             catch = [IHS_emissions.rename(columns={group_name+' allocated '+col+suffix: output_name+col+', '+suffix[1:]+' allocation factor', group_name+' allocated '+col+'_sigma'+suffix: output_name+col+', '+suffix[1:]+' allocation sigma'}, inplace=True) for col in emission_val_cols]\n",
    "#\n",
    "#     mats = material_emissions.rename(columns={'Product':'Target','Source/Object':'Product'}).drop_duplicates(subset=['Product']).drop(columns=['Code', 'Data Version', 'Type', 'Target/Process', 'Research Year', 'Country/Reg', 'Target', 'Value', 'Value unit', 'Value_sigma', 'Capacity unit', 'MeasType', 'Provenance'])\n",
    "#\n",
    "#     combined_factors = mats.sort_values('Product').reset_index(drop=True)\n",
    "#     combined_factors = combined_factors.merge(IHS_emissions, on='Product', how='outer')\n",
    "#     combined_factors = combined_factors.dropna(subset=combined_factors.columns[1:], how='all').reset_index(drop=True)\n",
    "#     return combined_factors\n",
    "#\n",
    "# def filter_df_for_type(df, types, type_col):\n",
    "#     return df[[i in types for i in df[type_col]]]\n",
    "#\n",
    "# def calculate_type_emissions(materials_df, product_df, emission_types:list, group_name:str, emissions_cols:list, emissions_cols_sigma:list, emission_val_cols:list, product_ratio_col, product_value_col, emission_type_col = 'Type'):\n",
    "#\n",
    "#     # Impose lists\n",
    "#     if type(emission_type_col) is str:\n",
    "#         emission_type_col = [emission_type_col]\n",
    "#         emission_types = [emission_types]\n",
    "#     if type(emission_types) is str:\n",
    "#         emission_types = [emission_types]\n",
    "#\n",
    "#     # Sum for groups\n",
    "#     grouped_df, grouped_df_sigma = materials_df.copy(), materials_df.copy()\n",
    "#     for emission_type_list, col in zip(emission_types, emission_type_col):\n",
    "#         if grouped_df.empty is False:\n",
    "#             grouped_df = filter_df_for_type(grouped_df, emission_type_list, col)\n",
    "#\n",
    "#     group_ems = np.sum(grouped_df[emissions_cols])\n",
    "#     group_ems_sigma = np.sum(grouped_df[emissions_cols_sigma])\n",
    "#\n",
    "#     # Loop through each value/gas column\n",
    "#     for val_column, gas_column, val_column_sigma, gas_column_sigma in zip(emission_val_cols, emissions_cols, [col + '_sigma' for col in emission_val_cols], emissions_cols_sigma):\n",
    "#\n",
    "#         # Allocate emissions for value and uncertainty\n",
    "#         product_df[group_name+' allocated ' + val_column] = group_ems[gas_column]*product_df[product_ratio_col]\n",
    "#         product_df[group_name+' allocated ' + val_column_sigma] = uncertainty_propagation('mult', group_ems[gas_column], group_ems_sigma[gas_column_sigma], product_df[product_ratio_col], product_df[product_ratio_col+'_sigma'], z=product_df[group_name+' allocated ' + val_column])\n",
    "#\n",
    "#         # Calculate emissions intensity for values and uncertainty\n",
    "#         product_df[group_name+' unit emission intensity ' + val_column] = product_df[group_name+' allocated ' + val_column]/product_df[product_value_col]\n",
    "#         product_df[group_name+' unit emission intensity ' + val_column_sigma] = uncertainty_propagation('mult', product_df[group_name+' allocated ' + val_column].values, product_df[group_name+' allocated ' + val_column_sigma].values, product_df[product_value_col].values, product_df[product_value_col+'_sigma'].values, z=product_df[group_name+' unit emission intensity ' + val_column])\n",
    "#\n",
    "#     return product_df\n",
    "#\n",
    "# def allocate_emissions(df:pd.DataFrame, emission_val_cols:list, mass_to_other_convs=False, mass_to_other_uncertainty=0.01, value_col= 'Mass, kg', ratio_col = 'Mass ratio'):\n",
    "#     # Get inputs to products\n",
    "#     df_ins = df[df['Type']!='By-Product']\n",
    "#     for column in emission_val_cols:\n",
    "#         if len(df_ins['cm_' + column + '_cradle-to-gate'].dropna()) == 0:\n",
    "#             df_ins['combined_' + column] = df_ins['ei_' + column + '_cradle-to-gate']\n",
    "#             df_ins['combined_' + column + '_sigma'] = df_ins['ei_' + column + '_cradle-to-gate_sigma']\n",
    "#         else:\n",
    "#             df_ins['combined_' + column] = np.nanmean([df_ins['ei_' + column + '_cradle-to-gate'], df_ins['cm_' + column + '_cradle-to-gate']], axis=0)\n",
    "#             df_ins['combined_' + column + '_sigma'] = np.nanmean([df_ins['ei_' + column + '_cradle-to-gate_sigma'], df_ins['cm_' + column + '_cradle-to-gate_sigma']], axis=0)\n",
    "#\n",
    "#     combined_cols = ['combined_' + column for column in emission_val_cols]\n",
    "#     combined_cols_sigma = ['combined_' + column + '_sigma' for column in emission_val_cols]\n",
    "#\n",
    "#     allocation = pd.DataFrame()\n",
    "#\n",
    "#     # Loop through each process\n",
    "#     for code in df['Code'].unique():\n",
    "#\n",
    "#         # Get by-products and mass ratios\n",
    "#         temp = df[df['Code']==code][['Code', 'Data Version', 'Source/Object', 'Type', 'Target/Process', 'Research Year', 'Country/Reg', 'Product', 'Value', 'Value unit', 'Value_sigma', 'Capacity unit', 'MeasType', 'Provenance']]\n",
    "#         a = temp.iloc[0]\n",
    "#         a['Source/Object'], a['Type'], a['Value'], a['Value unit'], a['Value_sigma'] = a['Product'], 'Product', float(1), 'kg/kg', float(0)\n",
    "#         a = pd.DataFrame(a.values.reshape(1,-1), columns=a.index)\n",
    "#         temp = temp[temp['Type']=='By-Product']\n",
    "#         temp = pd.concat([temp, a], axis=0)\n",
    "#\n",
    "#         # Convert values to energy if conversion exists in mass_to_enrgy_convs file\n",
    "#         if mass_to_other_convs is not False:\n",
    "#             # value_col, ratio_col, unit = 'Energy, MJ', 'Energy ratio', 'MJ'\n",
    "#             temp = temp.merge(mass_to_other_convs, how='left', left_on='Source/Object', right_on=mass_to_other_convs['Product'].str.upper())\n",
    "#             if temp['Conversion'].isnull().values.any():\n",
    "#                 continue\n",
    "#             else:\n",
    "#                 temp[value_col] = temp['Conversion']*abs(temp['Value'])\n",
    "#                 temp[value_col+'_sigma'] = uncertainty_propagation('mult', abs(temp['Value']), temp['Value_sigma'], temp['Conversion'], mass_to_other_uncertainty*temp['Conversion'], z=temp[value_col])\n",
    "#\n",
    "#         else:\n",
    "#             #value_col, ratio_col, unit = 'Mass, kg', 'Mass ratio', 'kg'\n",
    "#             temp[value_col] = abs(temp['Value'])\n",
    "#             temp[value_col+'_sigma'] = temp['Value_sigma']\n",
    "#\n",
    "#         # Get ratio of product vs all products+by-products\n",
    "#         temp[ratio_col] = temp[value_col]/sum(temp[value_col])\n",
    "#         temp[ratio_col+'_sigma'] = uncertainty_propagation('mult', temp[value_col], temp[value_col+'_sigma'], sum(temp[value_col]), sum(temp[value_col+'_sigma']), z=temp[ratio_col])\n",
    "#         ### -> Assumption of adding uncertainties together for sum(temp[value_col+'_sigma'])\n",
    "#\n",
    "#         # Get process emissions & allocate\n",
    "#         used_mats = df_ins[df_ins['Code']==code]\n",
    "#\n",
    "#         unique_types = list(used_mats['Type'].unique())\n",
    "#         group_names = ['Total'] + unique_types\n",
    "#         types_lists = [unique_types]+unique_types\n",
    "#\n",
    "#         for group_name, types in zip(group_names, types_lists):\n",
    "#             temp = calculate_type_emissions(used_mats, temp, types, group_name, combined_cols, combined_cols_sigma, emission_val_cols, ratio_col, value_col)\n",
    "#\n",
    "#         temp = calculate_type_emissions(used_mats, temp, [['Indirect Utilities'], ['ELECTRICITY']], 'Electricity', combined_cols, combined_cols_sigma, emission_val_cols, ratio_col, value_col, emission_type_col = ['Type', 'Source/Object'])\n",
    "#\n",
    "#         # Identify missing material emissions\n",
    "#         temp['Missing raw materials (>1% mass)'] = str(used_mats[(used_mats['Type']=='Raw Material') & (str(used_mats[combined_cols[0]])=='nan') & (used_mats['Value']> 0.01*np.sum(used_mats['Value']))]['Source/Object'].tolist())\n",
    "#\n",
    "#         # Identify missing utility emissions\n",
    "#         temp['Missing utilities'] = str(used_mats[(used_mats['Type']=='Utilities') & (str(used_mats[combined_cols[0]])=='nan')]['Source/Object'].tolist())\n",
    "#\n",
    "#         # Add current product to allocation list\n",
    "#         allocation = pd.concat([allocation, temp], axis=0)\n",
    "#     #return used_mats\n",
    "#     return allocation\n",
    "#\n",
    "# def convert_feedstocks_to_intermediates(material_emissions, product_group):\n",
    "#\n",
    "#     upstream_prods = product_group[[i in ['Primary chemicals', 'Intermediates'] for i in product_group['Product group']]]['Product']\n",
    "#     equivs_dict = dict(zip(product_group['Product'], product_group['Product group']))\n",
    "#     material_emissions.loc[(material_emissions['Type'] == 'Raw Material') & (material_emissions['Source/Object'].isin(upstream_prods)), 'Type'] = 'Diff'\n",
    "#     material_emissions.loc[(material_emissions['Type'] == 'Diff'), 'Type'] = material_emissions.loc[(material_emissions['Type'] == 'Diff')]['Source/Object'].replace(equivs_dict)\n",
    "#\n",
    "#     return material_emissions\n",
    "#\n",
    "# def get_direct_process_emissions(input_emissions, direct_emissions):\n",
    "#\n",
    "#     # Add emissions for each direct process\n",
    "#     process_emissions = input_emissions[[i in list(direct_emissions['Product']) for i in list(input_emissions['Product'])]][list(input_emissions.columns[:14])+['Product type', 'Product group']].drop_duplicates(subset=['Code','Target/Process','Product']).reset_index(drop=True)\n",
    "#     process_emissions['Type'], process_emissions['MeasType'] = 'Direct Process', 'Chemical'\n",
    "#     process_emissions['Source/Object'] = process_emissions['Product']\n",
    "#     process_emissions['Value'], process_emissions['Value_sigma'] = 1, 0\n",
    "#     process_emissions = process_emissions.merge(direct_emissions, on='Product', how='inner')\n",
    "#\n",
    "#     # Merge with all input emissions\n",
    "#     output_emissions = pd.concat((input_emissions, process_emissions), axis='index').sort_values(by=['Product', 'Target/Process', 'Code', 'Type', 'Source/Object'])\n",
    "#\n",
    "#     return output_emissions\n",
    "#\n",
    "# def calc_direct_process_convs(direct_emissions, product_process_match, ei_emissions):\n",
    "#     # Direct process emissions matching\n",
    "#     # Import direct emissions and match to existing products in ihsMaterials\n",
    "#     emission_val_cols = list(ei_emissions.columns[3:16])\n",
    "#     emission_val_cols_sigma = list(ei_emissions.columns[16:])\n",
    "#\n",
    "#     direct_emissions = direct_emissions[['Process']+list(direct_emissions.columns[-5:])]\n",
    "#     direct_emissions['Process'] = direct_emissions['Process'].str.upper()\n",
    "#\n",
    "#     direct_emissions = direct_emissions.merge(product_process_match, on='Process', how='right').dropna(subset=['Product']).drop(columns=['Process']).drop_duplicates(subset=['Product']).rename(columns={'est. CO2':'Carbon dioxide', 'est. CH4':'Methane','est. N2O':'Nitric oxide', 'est. CO2e_20a':'CO2e_20a', 'est. CO2e_100a': 'CO2e_100a'})\n",
    "#     direct_emissions['CO2e_500a'] = (direct_emissions['CO2e_100a']+direct_emissions['Carbon dioxide'])/2\n",
    "#\n",
    "#     uncertainty_ratio = 0.01\n",
    "#\n",
    "#     for col in emission_val_cols:\n",
    "#         if col in list(direct_emissions.columns):\n",
    "#             direct_emissions['ei_'+col+'_cradle-to-gate'] = direct_emissions[col].fillna(0).astype(float)\n",
    "#             direct_emissions['ei_'+col+'_cradle-to-gate_sigma'] = (direct_emissions[col].astype(float)*uncertainty_ratio)\n",
    "#             direct_emissions.drop(columns=[col], inplace=True)\n",
    "#         else:\n",
    "#             direct_emissions['ei_'+col+'_cradle-to-gate'] = 0\n",
    "#             direct_emissions['ei_'+col+'_cradle-to-gate_sigma'] = 0\n",
    "#\n",
    "#     return direct_emissions\n",
    "#\n",
    "# def get_direct_energy_emissions(material_emissions, direct_utl_conv, ei_emissions):\n",
    "#     \"\"\"Function for adding direct energy emissions to material emissions\"\"\"\n",
    "#     # Add direct emissions for each utility\n",
    "#     emission_val_cols = list(ei_emissions.columns[3:16])\n",
    "#     emission_val_cols_sigma = list(ei_emissions.columns[16:])\n",
    "#\n",
    "#     direct_utl_ems = material_emissions[material_emissions['Type']=='Indirect Utilities'][list(material_emissions.columns)[:14]+['Product type', 'Product group']]\n",
    "#     direct_utl_ems['Type'] = 'Direct Utilities'\n",
    "#     direct_utils = direct_utl_ems.merge(direct_utl_conv, left_on='Source/Object', right_on='Source', how='left').rename(columns={'Source':'ei_match'})\n",
    "#\n",
    "#     for col in emission_val_cols+emission_val_cols_sigma+['Value', 'Value_sigma']:\n",
    "#         direct_utils[col] = direct_utils[col].astype(float)\n",
    "#\n",
    "#     for gas in emission_val_cols:\n",
    "#         direct_utils['ei_'+gas+'_cradle-to-gate'] = direct_utils['Value']*direct_utils[gas]\n",
    "#         direct_utils['ei_'+gas+'_cradle-to-gate_sigma'] = uncertainty_propagation('mult', direct_utils['Value'], direct_utils['Value_sigma'], direct_utils[gas], direct_utils[gas+'_sigma'], z=direct_utils['ei_'+gas+'_cradle-to-gate'])\n",
    "#         direct_utils['ei_'+gas+'_conv_factor'] = direct_utils[gas]\n",
    "#         direct_utils['ei_'+gas+'_conv_factor_sigma'] = direct_utils[gas+'_sigma']\n",
    "#\n",
    "#     direct_utils.drop(columns=emission_val_cols+emission_val_cols_sigma, inplace=True)\n",
    "#\n",
    "#     # Merge with material emissions\n",
    "#     input_emissions = pd.concat((material_emissions, direct_utils), axis='index').sort_values(by=['Product', 'Target/Process', 'Code', 'Type', 'Source/Object'])\n",
    "#\n",
    "#     return input_emissions\n",
    "#\n",
    "# def get_upstream_emissions(input_mats, ei_emissions, cm_emissions, match_list_ei, match_list_cm):\n",
    "#     \"\"\"Function for getting upstream emissions including feedstocks and indirect energy usage from input materials\"\"\"\n",
    "#     # Match equivalent emissions to materials\n",
    "#     emission_val_cols = list(ei_emissions.columns[3:16])\n",
    "#     emission_val_cols_sigma = list(ei_emissions.columns[16:])\n",
    "#\n",
    "#     # EI matching\n",
    "#     material_emissions, upt_list = assign_emissions(input_mats, ei_emissions, 'Source/Object', 'Source', match_list=match_list_ei, db_name='ei', emission_val_cols=emission_val_cols, emission_val_cols_sigma=emission_val_cols_sigma)\n",
    "#\n",
    "#     # match_list_ei = pd.concat((match_list_ei, upt_list)).drop_duplicates(subset=['IHS'], keep='last')\n",
    "#\n",
    "#     # CM matching\n",
    "#     material_emissions, upt_list = assign_emissions(material_emissions, cm_emissions, 'Source/Object', 'Source', match_list=match_list_cm, db_name='cm', emission_val_cols=emission_val_cols, emission_val_cols_sigma=emission_val_cols_sigma)\n",
    "#\n",
    "#     # match_list_cm = pd.concat((match_list_cm, upt_list)).drop_duplicates(subset=['IHS'], keep='last')\n",
    "#\n",
    "#     # # Combine match lists\n",
    "#     # all_matches = match_list_ei[['IHS','ei']]\n",
    "#     # all_matches['cm'] = match_list_cm['cm']\n",
    "#     # all_matches.sort_values('IHS').reset_index(drop=True).to_csv(match_list_path, index=False)\n",
    "#\n",
    "#     # Create materials emissions\n",
    "#     material_emissions = material_emissions.drop_duplicates(subset=['Code', 'Source/Object']).reset_index(drop=True)\n",
    "#\n",
    "#     return material_emissions\n",
    "#\n",
    "# def filter_rows(df:pd.DataFrame, column:str, item:str, exact:bool=True):\n",
    "#     \"\"\"Function for finding best match for input item in a df column\"\"\"\n",
    "#     # If exact match enforced\n",
    "#     if exact:\n",
    "#         return df[df[column].str.lower() == item.lower()]\n",
    "#\n",
    "#     # If item is in string but not entire string\n",
    "#     else: return df[[item in row for row in df[column].str.lower()]]\n",
    "#\n",
    "# def uncertainty_propagation(calc:str, x:float, dx:float, y:float=1, dy:float=0, z:float=1, propagation_type:str='simple') -> float:\n",
    "#     \"\"\"Function for propagating uncertainty through calculations\"\"\"\n",
    "#     # Multiplication\n",
    "#     if calc == 'mult':\n",
    "#         xdiv = np.divide(dx, x, out=np.zeros_like(dx), where=x!=0)\n",
    "#         ydiv = np.divide(dy, y, out=np.zeros_like(dy), where=y!=0)\n",
    "#         if propagation_type == 'simple':\n",
    "#             return (xdiv + ydiv)*z\n",
    "#         elif propagation_type == 'stdev':\n",
    "#             return np.sqrt(pow(xdiv,2) + pow(ydiv,2))*z\n",
    "#         else: Exception('Specified propagation_type not recognised.')\n",
    "#\n",
    "#     # Addition\n",
    "#     elif calc == 'add':\n",
    "#         if propagation_type == 'simple':\n",
    "#             return abs(dx)+abs(dy)\n",
    "#         elif propagation_type == 'stdev':\n",
    "#             return np.sqrt(pow(dx,2) + pow(dy,2))\n",
    "#         else: Exception('Specified propagation_type not recognised.')\n",
    "#     else: Exception('Please specify calc of propagation')\n",
    "#\n",
    "# def assign_emissions(df:pd.DataFrame, emissions_df:pd.DataFrame, product_col:str, emissions_col:str,\n",
    "#                      product_val_col:str='Value', emission_val_cols:list=None, emission_val_cols_sigma:list= None, match_list=None, db_name:str='db', production_unit_conv:float=1) -> (pd.DataFrame, pd.DataFrame):\n",
    "#     \"\"\"These function assigns appropriate emissions values from EcoInvent or Carbonminds to products or materials in IHS given a pre-determined match from file or finding the best matches available\"\"\"\n",
    "#\n",
    "#     # Create values if none exist\n",
    "#     if match_list is None:\n",
    "#         match_list = {}\n",
    "#     if emission_val_cols is None:\n",
    "#         emission_val_cols = ['Cradle-to-gate']\n",
    "#     if emission_val_cols_sigma is None:\n",
    "#         emission_val_cols_sigma = ['Cradle-to-gate_sigma']\n",
    "#     product_val_col_sigma = product_val_col+'_sigma'\n",
    "#\n",
    "#     # Create columns to receive emissions, match name, emissions conversion factor\n",
    "#     val_col, match_name_col, conv_factor_col = pd.DataFrame(columns=emission_val_cols), [], pd.DataFrame(columns=emission_val_cols)\n",
    "#     # Columns for uncertainties of above\n",
    "#     val_col_sigma, conv_factor_col_sigma = pd.DataFrame(columns=emission_val_cols_sigma), pd.DataFrame(columns=emission_val_cols_sigma)\n",
    "#\n",
    "#     # Create match dictionary from appropriate match dataframe column\n",
    "#     length = len(emission_val_cols+emission_val_cols_sigma)\n",
    "#     if isinstance(match_list, pd.DataFrame) and db_name in match_list.columns:\n",
    "#         match_list = dict(zip(match_list['IHS'], match_list[db_name]))\n",
    "#\n",
    "#     # Loop through rows in assignment dataframe\n",
    "#     for row_num, row in tqdm(enumerate(df.iloc())):\n",
    "#\n",
    "#         # Check match_list for match\n",
    "#         if row[product_col].lower() in match_list.keys():\n",
    "#\n",
    "#             # If already defined as no match in db\n",
    "#             if str(match_list[row[product_col].lower()]) == '0':\n",
    "#                 correspondence = pd.DataFrame()\n",
    "#                 emission_val, name = pd.DataFrame(np.array([np.nan]*length).reshape(1,length), columns=emission_val_cols+emission_val_cols_sigma), np.nan\n",
    "#             # If match has corresponding db value\n",
    "#             else:\n",
    "#                 correspondence = filter_rows(emissions_df, emissions_col, match_list[row[product_col].lower()])\n",
    "#                 emission_val = correspondence[emission_val_cols+emission_val_cols_sigma]\n",
    "#                 name = correspondence.iloc[0][emissions_col]\n",
    "#\n",
    "#         # If no match yet assigned\n",
    "#         else:\n",
    "#             # Find correspondence in emissions dataframe\n",
    "#             correspondence = filter_rows(emissions_df, emissions_col, row[product_col].lower()) # Exact matching\n",
    "#\n",
    "#             if len(correspondence) == 0: # No exact match -> Try name contained within a match\n",
    "#                 correspondence = filter_rows(emissions_df, emissions_col, row[product_col].lower(), exact=False)\n",
    "#\n",
    "#                 if len(correspondence) > 1: # If multiple inexact matches\n",
    "#                         take = input('Enter number of best match for '+row[product_col].lower()+':\\n'+str(correspondence[emissions_col])+'\\n Type n to skip') # Ask user for best match\n",
    "#                         if take != 'n':\n",
    "#                             correspondence = correspondence[correspondence[emissions_col]==correspondence.loc[int(take)][emissions_col]] # Take best match\n",
    "#                         else:\n",
    "#                             correspondence = pd.DataFrame() # If none correspond then empty correspondence\n",
    "#\n",
    "#             if len(correspondence) == 0: # No exact match -> Try match contained within name\n",
    "#                 matching = emissions_df[[i in row[product_col].lower() for i in emissions_df[emissions_col]]] # Emission string contained in row matching\n",
    "#\n",
    "#                 if len(matching) > 0: # If multiple matches\n",
    "#                     correspondence = matching.iloc[np.argmax([len(i) for i in matching[emissions_col]])] # Take greatest length of match if multiple\n",
    "#                     emission_val = correspondence[emission_val_cols+emission_val_cols_sigma]\n",
    "#                     name = correspondence[emissions_col]\n",
    "#\n",
    "#                 else: emission_val, name = pd.DataFrame(np.array([np.nan]*length).reshape(1,length), columns=emission_val_cols+emission_val_cols_sigma), np.nan # If no matches identified\n",
    "#\n",
    "#             else:\n",
    "#                 emission_val = correspondence[emission_val_cols+emission_val_cols_sigma]\n",
    "#                 name = correspondence[emissions_col].values[0]\n",
    "#\n",
    "#             # Add match to match_list\n",
    "#             if len(correspondence) != 0:\n",
    "#                 if isinstance(correspondence, pd.DataFrame):\n",
    "#                     match_list.update({row[product_col].lower():correspondence.iloc[0]['Source']})\n",
    "#                 else:\n",
    "#                     match_list.update({row[product_col].lower():correspondence['Source']})\n",
    "#             else: match_list.update({row[product_col].lower():0})\n",
    "#             del correspondence\n",
    "#\n",
    "#         # Add matching values to dataframe\n",
    "#         val_col = pd.concat((val_col, row[product_val_col]*production_unit_conv*emission_val[emission_val_cols]))\n",
    "#\n",
    "#         # Calculate implied uncertainties and add to dataframe\n",
    "#         val_col_sigma = pd.concat((val_col_sigma,\n",
    "#                                    pd.DataFrame(uncertainty_propagation('mult', row[product_val_col], row[product_val_col_sigma], emission_val[emission_val_cols].values, emission_val[emission_val_cols_sigma].values, z=(row[product_val_col]*production_unit_conv*emission_val[emission_val_cols]).values)*production_unit_conv, columns=val_col_sigma.columns)))\n",
    "#\n",
    "#         # Add other parameters to parameter lists\n",
    "#         match_name_col += [name]\n",
    "#         conv_factor_col = pd.concat((conv_factor_col, emission_val[emission_val_cols]))\n",
    "#         conv_factor_col_sigma = pd.concat((conv_factor_col_sigma, emission_val[emission_val_cols_sigma]))\n",
    "#\n",
    "#     df[db_name + '_match'] = match_name_col\n",
    "#     for column, sigma_col in zip(emission_val_cols, emission_val_cols_sigma):\n",
    "#         df[db_name + '_' + column + '_cradle-to-gate'] = val_col[column].values\n",
    "#         df[db_name + '_' + column + '_cradle-to-gate_sigma'] = val_col_sigma[sigma_col].values\n",
    "#         df[db_name + '_' + column + '_conv_factor'] = conv_factor_col[column].values\n",
    "#         df[db_name + '_' + column + '_conv_factor_sigma'] = conv_factor_col_sigma[sigma_col].values\n",
    "#\n",
    "#     return df, pd.DataFrame.from_dict(match_list, orient='index').reset_index().rename(columns={'index':'IHS', 0:db_name})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c9aee0d2d16039c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c375f288fd351743",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
