{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Obtain process impacts by combining process outputs with impact factors\n",
    "\n",
    "Input - xml files (.spold is a form of .xml) downloaded from OpenLCA\n",
    "        impact factor .xml file also downloaded from OpenLCA\n",
    "\n",
    "Output - csv file of impact for each gas for all processes in xml files"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# Variable definition\n",
    "data_path = \"../data/\"\n",
    "lcaDataPath = data_path+\"EcoSpold01\"\n",
    "impactMethods_20 = data_path+ \"extra_inputs/EI_3_8_IPCC2013_GWP20a.xml\"\n",
    "impactMethods_100 = data_path+ \"extra_inputs/EI_3_8_IPCC2013_GWP100a.xml\"\n",
    "output_path = '../data/extracted/'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Define functions\n",
    "def to_listlist(inlist: list):\n",
    "    \"\"\"Ensures element is a list of lists even if single inner list\"\"\"\n",
    "    return [inlist] if type(inlist[0]) is not list else inlist\n",
    "\n",
    "def read_xml_attributes(filepath:str,branches:list,attributes:list,df=False):\n",
    "    \"\"\"This function creates a dataframe of attributes within an xml file.\\n\n",
    "    Inputs:\\n\n",
    "    filepath - path to xml file\\n\n",
    "    branches - list of successive branch choices\\n\n",
    "    attributes - attributes to be read from chosen branch\\n\n",
    "    Outputs:\\n\n",
    "    df - pandas dataframe of attributes for each end branch\\n\n",
    "    Requirements: pandas as pd, xml.etree.ElementTree as ET\"\"\"\n",
    "    if df is False: df = pd.DataFrame([],columns=[i for sublist in to_listlist(attributes) for i in sublist])\n",
    "    tree_loc = ET.parse(filepath). getroot()\n",
    "    branches, attributes = to_listlist(branches), to_listlist(attributes)\n",
    "    attr_values = dict()\n",
    "    for pathnum, path in enumerate(branches):\n",
    "        for branch in path:\n",
    "            for num,val in enumerate([branch in i.tag for i in tree_loc]):\n",
    "                if val:\n",
    "                    if branch is path[-1]:\n",
    "                        attr_values.update(dict(zip(attributes[pathnum],[tree_loc[num].attrib[i] if i else tree_loc[num].text for i in attributes[pathnum]])))\n",
    "                        if path is branches[-1]:\n",
    "                            df = pd.concat([df, pd.DataFrame(np.array([[i] for i in attr_values.values()]).transpose(),columns=attr_values.keys())],ignore_index=True)\n",
    "                    else:\n",
    "                        tree_loc=tree_loc[num]\n",
    "                        break\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Fetch and display impact factors\n",
    "impacts_20, impacts_100 = [read_xml_attributes(input_file,['dataset','flowData','exchange'],['name','category','subCategory','meanValue']).rename(columns={'meanValue':name}) for input_file, name in zip([impactMethods_20, impactMethods_100], ['CO2e_20a', 'CO2e_100a'])]\n",
    "impacts = impacts_20.merge(impacts_100, on=list(impacts_20.columns[:-1])).sort_values('name')\n",
    "impacts.to_csv(output_path+'EI_3_8_IPCC2013_CO2e.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate emissions from LCA data inventories\n",
    "# Load impact factors\n",
    "impacts = pd.read_csv(output_path+'EI_3_8_IPCC2013_CO2e.csv', index_col=0).reset_index(drop=True)\n",
    "\n",
    "# xml file metadata for row\n",
    "directory = lcaDataPath\n",
    "path = [['dataset','meta','process','reference'],['dataset','meta','process','geo']]\n",
    "attributes = [['name','generalComment'],['location']]\n",
    "\n",
    "# xml file output data\n",
    "output_attributes = ['name', 'category', 'subCategory', 'meanValue']\n",
    "output_branches = ['dataset', 'flowData', 'exchange']\n",
    "\n",
    "# impact data (CO2 calculated + all others)\n",
    "co2e_cols = ['CO2e_20a', 'CO2e_100a']\n",
    "impact_columns = list(impacts[['name']+co2e_cols].drop_duplicates().sort_values('name')['name'].values)\n",
    "\n",
    "# Function calculating corresponding emissions for all files in subset and outputting parquet file carried out in batch and can be parallelised\n",
    "file_list = os.listdir(directory)\n",
    "attributes = to_listlist(attributes)\n",
    "batch_size = 100\n",
    "\n",
    "def calc_xml_emissions(num):\n",
    "    subset = file_list[num:num+batch_size]\n",
    "    df_new = pd.DataFrame([],columns=[j for i in attributes for j in i] + co2e_cols + impact_columns)\n",
    "    df_all = df_new.copy()\n",
    "    for file in subset:\n",
    "        df = read_xml_attributes(os.path.join(directory, file), path, attributes, df_new)\n",
    "        outputs = read_xml_attributes(os.path.join(directory, file), output_branches, output_attributes)\n",
    "        outputs = outputs.merge(impacts)\n",
    "        outputs[['meanValue']+co2e_cols] = outputs[['meanValue']+co2e_cols].apply(pd.to_numeric)\n",
    "        df[co2e_cols] = [sum(outputs['meanValue']*outputs[impact_col]) for impact_col in co2e_cols]\n",
    "        if len(outputs) != 0:\n",
    "            summary = outputs[['name','meanValue']].groupby('name').sum()\n",
    "            df[list(summary.index)] = list(summary['meanValue'].values)\n",
    "        df_all = pd.concat((df_all, df))\n",
    "    df_all.to_parquet(data_path+'process_emissions/process_emissions_'+str(num)+'-'+str(num+batch_size)+'.parquet')\n",
    "\n",
    "list(map(calc_xml_emissions, range(0, 11000, batch_size)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "cm_emissions = pd.concat(pd.read_parquet(data_path+'process_emissions/'+file) for file in os.listdir(data_path+'process_emissions/'))\n",
    "\n",
    "cm_emissions.sort_values(['name','location']).to_csv(data_path+'process_emissions/cm_emissions.csv', index=False)\n",
    "\n",
    "# ei_emissions = pd.concat(pd.read_parquet(data_path+'process_emissions/'+file) for file in os.listdir(data_path+'process_emissions/'))\n",
    "# ei_emissions.sort_values(['name','location']).to_csv('C:/Users\\lukec\\OneDrive - University of Cambridge\\PhD\\Data\\EcoInvent\\process_emissions\\ei_emissions.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "## Add uncertainties\n",
    "input_path = ''\n",
    "ei = pd.read_csv(input_path+'ei_emissions_IPCC2013.csv')\n",
    "cm = pd.read_csv(input_path+'cm_emissions_IPCC2013.csv')\n",
    "\n",
    "uncertainty_factor = 0.1\n",
    "for col in ei.columns[3:]:\n",
    "    ei[col+'_sigma'] = ei[col]*uncertainty_factor\n",
    "    cm[col+'_sigma'] = cm[col]*uncertainty_factor\n",
    "    \n",
    "ei.to_csv(input_path+'ei_emissions_IPCC2013_uncertainties.csv')\n",
    "cm.to_csv(input_path+'cm_emissions_IPCC2013_uncertainties.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
